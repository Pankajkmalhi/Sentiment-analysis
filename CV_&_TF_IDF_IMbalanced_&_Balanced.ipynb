{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"IMDBDataset.csv\")\n",
        "\n",
        "# Data Preprocessing\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    # Remove non-alphanumeric characters and convert to lowercase\n",
        "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text.lower())\n",
        "    # Tokenization and removing stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "data['processed_text'] = data['review'].apply(preprocess_text)\n",
        "\n",
        "# Save the preprocessed dataset to a separate file\n",
        "data.to_csv(\"preprocessed_imdb_reviews.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA7mw49_xN8m",
        "outputId": "976854b4-ee08-4965-a885-22ecad991690"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Subset making of the dataset**"
      ],
      "metadata": {
        "id": "L1LZwrafwRdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the preprocessed dataset\n",
        "preprocessed_data = pd.read_csv(\"preprocessed_imdb_reviews.csv\")\n",
        "\n",
        "# Select a random subset of 1200 rows\n",
        "subset_data = preprocessed_data.sample(n=5000, random_state=42)\n",
        "\n",
        "# Save the subset dataset to a new file\n",
        "subset_data.to_csv(\"subset_preprocessed_imdb_reviews.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "0nDPGT0OwRCh"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the original dataset\n",
        "original_data = pd.read_csv(\"IMDBDataset.csv\")\n",
        "\n",
        "# Print details of the original dataset\n",
        "print(\"Original Dataset Details:\")\n",
        "print(\"Number of rows:\", original_data.shape[0])\n",
        "print(\"Number of columns:\", original_data.shape[1])\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(original_data.head())\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "preprocessed_data = pd.read_csv(\"preprocessed_imdb_reviews.csv\")\n",
        "\n",
        "# Print details of the preprocessed dataset\n",
        "print(\"\\nPreprocessed Dataset Details:\")\n",
        "print(\"Number of rows:\", preprocessed_data.shape[0])\n",
        "print(\"Number of columns:\", preprocessed_data.shape[1])\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(preprocessed_data.head())\n",
        "\n",
        "#subset Dataset\n",
        "subset_preprocessed_data = pd.read_csv(\"subset_preprocessed_imdb_reviews.csv\")\n",
        "\n",
        "# Print details of the preprocessed dataset\n",
        "print(\"\\nSubset Preprocessed Dataset Details:\")\n",
        "print(\"Number of rows:\", subset_preprocessed_data.shape[0])\n",
        "print(\"Number of columns:\", subset_preprocessed_data.shape[1])\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(subset_preprocessed_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UG29IPg7bPJ",
        "outputId": "4887c908-c12d-41e2-ad94-2db2f8d5d689"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Dataset Details:\n",
            "Number of rows: 50000\n",
            "Number of columns: 2\n",
            "\n",
            "First few rows:\n",
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "\n",
            "Preprocessed Dataset Details:\n",
            "Number of rows: 50000\n",
            "Number of columns: 3\n",
            "\n",
            "First few rows:\n",
            "                                              review sentiment  \\\n",
            "0  One of the other reviewers has mentioned that ...  positive   \n",
            "1  A wonderful little production. <br /><br />The...  positive   \n",
            "2  I thought this was a wonderful way to spend ti...  positive   \n",
            "3  Basically there's a family where a little boy ...  negative   \n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
            "\n",
            "                                      processed_text  \n",
            "0  one reviewer mentioned watching 1 oz episode h...  \n",
            "1  wonderful little production filming technique ...  \n",
            "2  thought wonderful way spend time hot summer we...  \n",
            "3  basically family little boy jake think zombie ...  \n",
            "4  petter mattei love time money visually stunnin...  \n",
            "\n",
            "Subset Preprocessed Dataset Details:\n",
            "Number of rows: 5000\n",
            "Number of columns: 3\n",
            "\n",
            "First few rows:\n",
            "                                              review sentiment  \\\n",
            "0  I really liked this Summerslam due to the look...  positive   \n",
            "1  Not many television shows appeal to quite as m...  positive   \n",
            "2  The film quickly gets to a major chase scene w...  negative   \n",
            "3  Jane Austen would definitely approve of this o...  positive   \n",
            "4  Expectations were somewhat high for me when I ...  negative   \n",
            "\n",
            "                                      processed_text  \n",
            "0  really liked summerslam due look arena curtain...  \n",
            "1  many television show appeal quite many differe...  \n",
            "2  film quickly get major chase scene ever increa...  \n",
            "3  jane austen would definitely approve one gwyne...  \n",
            "4  expectation somewhat high went see movie thoug...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Future engineering count Vectorization**"
      ],
      "metadata": {
        "id": "mkREK_IEibl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "preprocessed_data = pd.read_csv(\"subset_preprocessed_imdb_reviews.csv\")\n",
        "\n",
        "# Extract the preprocessed text data\n",
        "processed_text = preprocessed_data['processed_text']\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "count_vectorizer = CountVectorizer(max_features=5000)  # Limiting the number of features to 5000\n",
        "\n",
        "# Perform Count Vectorization\n",
        "X = count_vectorizer.fit_transform(processed_text)\n",
        "\n",
        "# Print the shape of the feature matrix\n",
        "print(\"Shape of the feature matrix after Count Vectorization:\", X.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhj4NIW9ieWn",
        "outputId": "2accc7f6-99f0-4583-d7d1-2dec3c83e47f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the feature matrix after Count Vectorization: (5000, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Count Vectorization**"
      ],
      "metadata": {
        "id": "VqnrwUMmnHel"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **for imbalanced**"
      ],
      "metadata": {
        "id": "7GOzjV130s0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic regerassion**"
      ],
      "metadata": {
        "id": "TfJUQOzFj6pj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "preprocessed_data = pd.read_csv(\"subset_preprocessed_imdb_reviews.csv\")\n",
        "\n",
        "# Shuffle the dataset\n",
        "preprocessed_data = shuffle(preprocessed_data, random_state=42)\n",
        "\n",
        "# Extract the preprocessed text data and labels\n",
        "processed_text = preprocessed_data['processed_text']\n",
        "labels = preprocessed_data['sentiment']\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "count_vectorizer = CountVectorizer(max_features=5000)  # Limiting the number of features to 5000\n",
        "\n",
        "# Perform Count Vectorization\n",
        "X = count_vectorizer.fit_transform(processed_text)\n",
        "\n",
        "# Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model with increased max_iter\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Cross-Validation Approach\n",
        "cv_f1_scores = cross_val_score(lr_model, X, labels, cv=5, scoring='f1_weighted', error_score='raise')\n",
        "cv_accuracy_scores = cross_val_score(lr_model, X, labels, cv=5, scoring='accuracy', error_score='raise')\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_test = lr_model.predict(X_test)\n",
        "\n",
        "# Predict on train set\n",
        "y_pred_train = lr_model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on test set\n",
        "test_classification_report = classification_report(y_test, y_pred_test, output_dict=True, target_names=['negative', 'positive'])\n",
        "test_f1_score = test_classification_report['weighted avg']['f1-score']\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "# Evaluate the model on train set\n",
        "train_classification_report = classification_report(y_train, y_pred_train, output_dict=True, target_names=['negative', 'positive'])\n",
        "train_f1_score = train_classification_report['weighted avg']['f1-score']\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "\n",
        "# Print Results\n",
        "print(\"Logistic Regression Model Results:\")\n",
        "print(\"-------------------------------------------------------\")\n",
        "print(\"CV=N Report F1-Score: {:.4f}\".format(cv_f1_scores.mean()))\n",
        "print(\"CV=N Accuracy: {:.4f}\".format(cv_accuracy_scores.mean()))\n",
        "print(\"Test Set Report F1-Score: {:.4f}\".format(test_f1_score))\n",
        "print(\"Test Set Accuracy: {:.4f}\".format(test_accuracy))\n",
        "print(\"Train Set Report F1-Score: {:.4f}\".format(train_f1_score))\n",
        "print(\"Train Set Accuracy: {:.4f}\".format(train_accuracy))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbXwz-czj5DR",
        "outputId": "5318937d-c930-4e03-cc41-25d7ee81092a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Model Results:\n",
            "-------------------------------------------------------\n",
            "CV=N Report F1-Score: 0.8330\n",
            "CV=N Accuracy: 0.8330\n",
            "Test Set Report F1-Score: 0.8420\n",
            "Test Set Accuracy: 0.8420\n",
            "Train Set Report F1-Score: 0.9995\n",
            "Train Set Accuracy: 0.9995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM **model**"
      ],
      "metadata": {
        "id": "eawlImwymGv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "preprocessed_data = pd.read_csv(\"subset_preprocessed_imdb_reviews.csv\")\n",
        "\n",
        "# Shuffle the dataset\n",
        "preprocessed_data = shuffle(preprocessed_data, random_state=42)\n",
        "\n",
        "# Extract the preprocessed text data and labels\n",
        "processed_text = preprocessed_data['processed_text']\n",
        "labels = preprocessed_data['sentiment']\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "count_vectorizer = CountVectorizer(max_features=5000)  # Limiting the number of features to 5000\n",
        "\n",
        "# Perform Count Vectorization\n",
        "X = count_vectorizer.fit_transform(processed_text)\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train SVM model\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Cross-Validation Approach\n",
        "cv_f1_scores = cross_val_score(svm_model, X, encoded_labels, cv=5, scoring='f1')\n",
        "cv_accuracy_scores = cross_val_score(svm_model, X, encoded_labels, cv=5, scoring='accuracy')\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_test = svm_model.predict(X_test)\n",
        "\n",
        "# Predict on train set\n",
        "y_pred_train = svm_model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on test set\n",
        "test_f1_score = classification_report(y_test, y_pred_test, output_dict=True)['weighted avg']['f1-score']\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "# Evaluate the model on train set\n",
        "train_f1_score = classification_report(y_train, y_pred_train, output_dict=True)['weighted avg']['f1-score']\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "\n",
        "# Print Results\n",
        "print(\"Support Vector Machine (SVM) Model Results:\")\n",
        "print(\"-------------------------------------------------------\")\n",
        "print(\"CV=N Report F1-Score: {:.4f}\".format(cv_f1_scores.mean()))\n",
        "print(\"CV=N Accuracy: {:.4f}\".format(cv_accuracy_scores.mean()))\n",
        "print(\"Test Set Report F1-Score: {:.4f}\".format(test_f1_score))\n",
        "print(\"Test Set Accuracy: {:.4f}\".format(test_accuracy))\n",
        "print(\"Train Set Report F1-Score: {:.4f}\".format(train_f1_score))\n",
        "print(\"Train Set Accuracy: {:.4f}\".format(train_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkIlfXS-mJvY",
        "outputId": "1d250639-b87e-49db-85d8-132fbe2210e4"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Machine (SVM) Model Results:\n",
            "-------------------------------------------------------\n",
            "CV=N Report F1-Score: 0.8351\n",
            "CV=N Accuracy: 0.8266\n",
            "Test Set Report F1-Score: 0.8317\n",
            "Test Set Accuracy: 0.8320\n",
            "Train Set Report F1-Score: 0.9672\n",
            "Train Set Accuracy: 0.9673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**"
      ],
      "metadata": {
        "id": "OTZK9T-wmjZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "preprocessed_data = pd.read_csv(\"subset_preprocessed_imdb_reviews.csv\")\n",
        "\n",
        "# Shuffle the dataset\n",
        "preprocessed_data = shuffle(preprocessed_data, random_state=42)\n",
        "\n",
        "# Extract the preprocessed text data and labels\n",
        "processed_text = preprocessed_data['processed_text']\n",
        "labels = preprocessed_data['sentiment']\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "count_vectorizer = CountVectorizer(max_features=5000)  # Limiting the number of features to 5000\n",
        "\n",
        "# Perform Count Vectorization\n",
        "X = count_vectorizer.fit_transform(processed_text)\n",
        "\n",
        "# Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest model\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Cross-Validation Approach\n",
        "cv_f1_scores = cross_val_score(rf_model, X, encoded_labels, cv=5, scoring='f1')\n",
        "cv_accuracy_scores = cross_val_score(rf_model, X, encoded_labels, cv=5, scoring='accuracy')\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_test = rf_model.predict(X_test)\n",
        "\n",
        "# Predict on train set\n",
        "y_pred_train = rf_model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on test set\n",
        "test_f1_score = classification_report(y_test, y_pred_test, output_dict=True)['weighted avg']['f1-score']\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "# Evaluate the model on train set\n",
        "train_f1_score = classification_report(y_train, y_pred_train, output_dict=True)['weighted avg']['f1-score']\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "\n",
        "# Print Results\n",
        "print(\"Random Forest Model Results:\")\n",
        "print(\"-------------------------------------------------------\")\n",
        "print(\"CV=N Report F1-Score: {:.4f}\".format(cv_f1_scores.mean()))\n",
        "print(\"CV=N Accuracy: {:.4f}\".format(cv_accuracy_scores.mean()))\n",
        "print(\"Test Set Report F1-Score: {:.4f}\".format(test_f1_score))\n",
        "print(\"Test Set Accuracy: {:.4f}\".format(test_accuracy))\n",
        "print(\"Train Set Report F1-Score: {:.4f}\".format(train_f1_score))\n",
        "print(\"Train Set Accuracy: {:.4f}\".format(train_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs35WFOTmmaD",
        "outputId": "40f4956a-b085-443b-80a3-f5751e479ee8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Model Results:\n",
            "-------------------------------------------------------\n",
            "CV=N Report F1-Score: 0.8340\n",
            "CV=N Accuracy: 0.8308\n",
            "Test Set Report F1-Score: 0.8510\n",
            "Test Set Accuracy: 0.8510\n",
            "Train Set Report F1-Score: 1.0000\n",
            "Train Set Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient Boosting**"
      ],
      "metadata": {
        "id": "7dwoaxmbmvjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "preprocessed_data = pd.read_csv(\"subset_preprocessed_imdb_reviews.csv\")\n",
        "\n",
        "# Shuffle the dataset\n",
        "preprocessed_data = shuffle(preprocessed_data, random_state=42)\n",
        "\n",
        "# Extract the preprocessed text data and labels\n",
        "processed_text = preprocessed_data['processed_text']\n",
        "labels = preprocessed_data['sentiment']\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "count_vectorizer = CountVectorizer(max_features=5000)  # Limiting the number of features to 5000\n",
        "\n",
        "# Perform Count Vectorization\n",
        "X = count_vectorizer.fit_transform(processed_text)\n",
        "\n",
        "# Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Gradient Boosting model\n",
        "gb_model = GradientBoostingClassifier()\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# Cross-Validation Approach\n",
        "cv_f1_scores = cross_val_score(gb_model, X, encoded_labels, cv=5, scoring='f1')\n",
        "cv_accuracy_scores = cross_val_score(gb_model, X, encoded_labels, cv=5, scoring='accuracy')\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_test = gb_model.predict(X_test)\n",
        "\n",
        "# Predict on train set\n",
        "y_pred_train = gb_model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on test set\n",
        "test_f1_score = classification_report(y_test, y_pred_test, output_dict=True)['weighted avg']['f1-score']\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "# Evaluate the model on train set\n",
        "train_f1_score = classification_report(y_train, y_pred_train, output_dict=True)['weighted avg']['f1-score']\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "\n",
        "# Print Results\n",
        "print(\"Gradient Boosting Model Results:\")\n",
        "print(\"-------------------------------------------------------\")\n",
        "print(\"CV=N Report F1-Score: {:.4f}\".format(cv_f1_scores.mean()))\n",
        "print(\"CV=N Accuracy: {:.4f}\".format(cv_accuracy_scores.mean()))\n",
        "print(\"Test Set Report F1-Score: {:.4f}\".format(test_f1_score))\n",
        "print(\"Test Set Accuracy: {:.4f}\".format(test_accuracy))\n",
        "print(\"Train Set Report F1-Score: {:.4f}\".format(train_f1_score))\n",
        "print(\"Train Set Accuracy: {:.4f}\".format(train_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B8I3xNqmzsI",
        "outputId": "96470bd6-6395-4c2f-d661-ef2ed8d92033"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Model Results:\n",
            "-------------------------------------------------------\n",
            "CV=N Report F1-Score: 0.8198\n",
            "CV=N Accuracy: 0.8088\n",
            "Test Set Report F1-Score: 0.8374\n",
            "Test Set Accuracy: 0.8380\n",
            "Train Set Report F1-Score: 0.8661\n",
            "Train Set Accuracy: 0.8665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TF/IDF Approach**"
      ],
      "metadata": {
        "id": "-fs7Ab1dnPro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic regerassion**"
      ],
      "metadata": {
        "id": "xDyEGueWoIzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "preprocessed_data = pd.read_csv(\"subset_preprocessed_imdb_reviews.csv\")\n",
        "\n",
        "# Shuffle the dataset\n",
        "preprocessed_data = shuffle(preprocessed_data, random_state=42)\n",
        "\n",
        "# Extract the preprocessed text data and labels\n",
        "processed_text = preprocessed_data['processed_text']\n",
        "labels = preprocessed_data['sentiment']\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Initialize TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limiting the number of features to 5000\n",
        "\n",
        "# Perform TF-IDF Vectorization\n",
        "X = tfidf_vectorizer.fit_transform(processed_text)\n",
        "\n",
        "# Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Cross-Validation Approach\n",
        "cv_f1_scores = cross_val_score(lr_model, X, encoded_labels, cv=5, scoring='f1')\n",
        "cv_accuracy_scores = cross_val_score(lr_model, X, encoded_labels, cv=5, scoring='accuracy')\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_test = lr_model.predict(X_test)\n",
        "\n",
        "# Predict on train set\n",
        "y_pred_train = lr_model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on test set\n",
        "test_f1_score = classification_report(y_test, y_pred_test, output_dict=True)['weighted avg']['f1-score']\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "# Evaluate the model on train set\n",
        "train_f1_score = classification_report(y_train, y_pred_train, output_dict=True)['weighted avg']['f1-score']\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "\n",
        "# Print Results\n",
        "print(\"Logistic Regression Model Results with TF-IDF approach:\")\n",
        "print(\"-------------------------------------------------------\")\n",
        "print(\"CV=N Report F1-Score: {:.4f}\".format(cv_f1_scores.mean()))\n",
        "print(\"CV=N Accuracy: {:.4f}\".format(cv_accuracy_scores.mean()))\n",
        "print(\"Test Set Report F1-Score: {:.4f}\".format(test_f1_score))\n",
        "print(\"Test Set Accuracy: {:.4f}\".format(test_accuracy))\n",
        "print(\"Train Set Report F1-Score: {:.4f}\".format(train_f1_score))\n",
        "print(\"Train Set Accuracy: {:.4f}\".format(train_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L89lwCmaoOyG",
        "outputId": "51a34f03-8e58-4287-b086-0403a6351589"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Model Results with TF-IDF approach:\n",
            "-------------------------------------------------------\n",
            "CV=N Report F1-Score: 0.8560\n",
            "CV=N Accuracy: 0.8518\n",
            "Test Set Report F1-Score: 0.8660\n",
            "Test Set Accuracy: 0.8660\n",
            "Train Set Report F1-Score: 0.9390\n",
            "Train Set Accuracy: 0.9390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM**"
      ],
      "metadata": {
        "id": "BflzMYSVoSmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "preprocessed_data = pd.read_csv(\"subset_preprocessed_imdb_reviews.csv\")\n",
        "\n",
        "# Shuffle the dataset\n",
        "preprocessed_data = shuffle(preprocessed_data, random_state=42)\n",
        "\n",
        "# Extract the preprocessed text data and labels\n",
        "processed_text = preprocessed_data['processed_text']\n",
        "labels = preprocessed_data['sentiment']\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Initialize TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limiting the number of features to 5000\n",
        "\n",
        "# Perform TF-IDF Vectorization\n",
        "X = tfidf_vectorizer.fit_transform(processed_text)\n",
        "\n",
        "# Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train SVM model\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Cross-Validation Approach\n",
        "cv_f1_scores = cross_val_score(svm_model, X, encoded_labels, cv=5, scoring='f1')\n",
        "cv_accuracy_scores = cross_val_score(svm_model, X, encoded_labels, cv=5, scoring='accuracy')\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_test = svm_model.predict(X_test)\n",
        "\n",
        "# Predict on train set\n",
        "y_pred_train = svm_model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on test set\n",
        "test_f1_score = classification_report(y_test, y_pred_test, output_dict=True)['weighted avg']['f1-score']\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "# Evaluate the model on train set\n",
        "train_f1_score = classification_report(y_train, y_pred_train, output_dict=True)['weighted avg']['f1-score']\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "\n",
        "# Print Results\n",
        "print(\"Support Vector Machine (SVM) Model Results with TF-IDF approach:\")\n",
        "print(\"-------------------------------------------------------\")\n",
        "print(\"CV=N Report F1-Score: {:.4f}\".format(cv_f1_scores.mean()))\n",
        "print(\"CV=N Accuracy: {:.4f}\".format(cv_accuracy_scores.mean()))\n",
        "print(\"Test Set Report F1-Score: {:.4f}\".format(test_f1_score))\n",
        "print(\"Test Set Accuracy: {:.4f}\".format(test_accuracy))\n",
        "print(\"Train Set Report F1-Score: {:.4f}\".format(train_f1_score))\n",
        "print(\"Train Set Accuracy: {:.4f}\".format(train_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83rA9ZKAoUjf",
        "outputId": "822cbb6b-0a59-404b-ae57-e95cdc68f0ff"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Machine (SVM) Model Results with TF-IDF approach:\n",
            "-------------------------------------------------------\n",
            "CV=N Report F1-Score: 0.8573\n",
            "CV=N Accuracy: 0.8528\n",
            "Test Set Report F1-Score: 0.8640\n",
            "Test Set Accuracy: 0.8640\n",
            "Train Set Report F1-Score: 0.9965\n",
            "Train Set Accuracy: 0.9965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**"
      ],
      "metadata": {
        "id": "SYod7aVPoX8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "preprocessed_data = pd.read_csv(\"subset_preprocessed_imdb_reviews.csv\")\n",
        "\n",
        "# Shuffle the dataset\n",
        "preprocessed_data = shuffle(preprocessed_data, random_state=42)\n",
        "\n",
        "# Extract the preprocessed text data and labels\n",
        "processed_text = preprocessed_data['processed_text']\n",
        "labels = preprocessed_data['sentiment']\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Initialize TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limiting the number of features to 5000\n",
        "\n",
        "# Perform TF-IDF Vectorization\n",
        "X = tfidf_vectorizer.fit_transform(processed_text)\n",
        "\n",
        "# Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest model\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Cross-Validation Approach\n",
        "cv_f1_scores = cross_val_score(rf_model, X, encoded_labels, cv=5, scoring='f1')\n",
        "cv_accuracy_scores = cross_val_score(rf_model, X, encoded_labels, cv=5, scoring='accuracy')\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_test = rf_model.predict(X_test)\n",
        "\n",
        "# Predict on train set\n",
        "y_pred_train = rf_model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on test set\n",
        "test_f1_score = classification_report(y_test, y_pred_test, output_dict=True)['weighted avg']['f1-score']\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "# Evaluate the model on train set\n",
        "train_f1_score = classification_report(y_train, y_pred_train, output_dict=True)['weighted avg']['f1-score']\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "\n",
        "# Print Results\n",
        "print(\"Random Forest Model Results with TF-IDF approach:\")\n",
        "print(\"-------------------------------------------------------\")\n",
        "print(\"CV=N Report F1-Score: {:.4f}\".format(cv_f1_scores.mean()))\n",
        "print(\"CV=N Accuracy: {:.4f}\".format(cv_accuracy_scores.mean()))\n",
        "print(\"Test Set Report F1-Score: {:.4f}\".format(test_f1_score))\n",
        "print(\"Test Set Accuracy: {:.4f}\".format(test_accuracy))\n",
        "print(\"Train Set Report F1-Score: {:.4f}\".format(train_f1_score))\n",
        "print(\"Train Set Accuracy: {:.4f}\".format(train_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0BBN1BIoctI",
        "outputId": "02a9a06c-c80f-46f2-a51d-302f2d2ffbac"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Model Results with TF-IDF approach:\n",
            "-------------------------------------------------------\n",
            "CV=N Report F1-Score: 0.8308\n",
            "CV=N Accuracy: 0.8276\n",
            "Test Set Report F1-Score: 0.8480\n",
            "Test Set Accuracy: 0.8480\n",
            "Train Set Report F1-Score: 1.0000\n",
            "Train Set Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient boosting**"
      ],
      "metadata": {
        "id": "Aeqxq12hokiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "preprocessed_data = pd.read_csv(\"subset_preprocessed_imdb_reviews.csv\")\n",
        "\n",
        "# Shuffle the dataset\n",
        "preprocessed_data = shuffle(preprocessed_data, random_state=42)\n",
        "\n",
        "# Extract the preprocessed text data and labels\n",
        "processed_text = preprocessed_data['processed_text']\n",
        "labels = preprocessed_data['sentiment']\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Initialize TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limiting the number of features to 5000\n",
        "\n",
        "# Perform TF-IDF Vectorization\n",
        "X = tfidf_vectorizer.fit_transform(processed_text)\n",
        "\n",
        "# Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Gradient Boosting model\n",
        "gb_model = GradientBoostingClassifier()\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# Cross-Validation Approach\n",
        "cv_f1_scores = cross_val_score(gb_model, X, encoded_labels, cv=5, scoring='f1')\n",
        "cv_accuracy_scores = cross_val_score(gb_model, X, encoded_labels, cv=5, scoring='accuracy')\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_test = gb_model.predict(X_test)\n",
        "\n",
        "# Predict on train set\n",
        "y_pred_train = gb_model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on test set\n",
        "test_f1_score = classification_report(y_test, y_pred_test, output_dict=True)['weighted avg']['f1-score']\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "# Evaluate the model on train set\n",
        "train_f1_score = classification_report(y_train, y_pred_train, output_dict=True)['weighted avg']['f1-score']\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "\n",
        "# Print Results\n",
        "print(\"Gradient Boosting Model Results with TF-IDF approach:\")\n",
        "print(\"-------------------------------------------------------\")\n",
        "print(\"CV=N Report F1-Score: {:.4f}\".format(cv_f1_scores.mean()))\n",
        "print(\"CV=N Accuracy: {:.4f}\".format(cv_accuracy_scores.mean()))\n",
        "print(\"Test Set Report F1-Score: {:.4f}\".format(test_f1_score))\n",
        "print(\"Test Set Accuracy: {:.4f}\".format(test_accuracy))\n",
        "print(\"Train Set Report F1-Score: {:.4f}\".format(train_f1_score))\n",
        "print(\"Train Set Accuracy: {:.4f}\".format(train_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6oz3rgConHp",
        "outputId": "d6ca557f-31d5-4524-c22a-c21a32d9bee7"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Model Results with TF-IDF approach:\n",
            "-------------------------------------------------------\n",
            "CV=N Report F1-Score: 0.8161\n",
            "CV=N Accuracy: 0.8036\n",
            "Test Set Report F1-Score: 0.8265\n",
            "Test Set Accuracy: 0.8270\n",
            "Train Set Report F1-Score: 0.8958\n",
            "Train Set Accuracy: 0.8960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Balanced Dataset**"
      ],
      "metadata": {
        "id": "lUehWqFg0Z5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Future Engineering TF-IDF**"
      ],
      "metadata": {
        "id": "jKI6rwxe3R3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "preprocessed_data = pd.read_csv(\"subset_preprocessed_imdb_reviews.csv\")\n",
        "\n",
        "# Extract the preprocessed text data\n",
        "processed_text = preprocessed_data['processed_text']\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limiting the number of features to 5000\n",
        "\n",
        "\n",
        "# Perform TF-IDF Vectorization\n",
        "X = tfidf_vectorizer.fit_transform(processed_text)\n",
        "\n",
        "# Print the shape of the feature matrix\n",
        "print(\"Shape of the feature matrix after TF-IDF Vectorization:\", X.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS94dqAn3bjI",
        "outputId": "06f052fd-a8cb-4fb1-b31b-28de411464c4"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the feature matrix after TF-IDF Vectorization: (5000, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic regression**"
      ],
      "metadata": {
        "id": "3VyHHFYM0e0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "preprocessed_data = pd.read_csv(\"subset_preprocessed_imdb_reviews.csv\")\n",
        "\n",
        "# Extract the preprocessed text data and labels\n",
        "processed_text = preprocessed_data['processed_text']\n",
        "labels = preprocessed_data['sentiment']\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "count_vectorizer = CountVectorizer(max_features=5000)  # Limiting the number of features to 5000\n",
        "\n",
        "# Perform Count Vectorization\n",
        "X = count_vectorizer.fit_transform(processed_text)\n",
        "\n",
        "# Apply SMOTE to balance the dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, labels)\n",
        "\n",
        "# Train/Test Split on balanced dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Cross-validation for train set\n",
        "cv_f1_scores_train = cross_val_score(lr_model, X_train, y_train, cv=5, scoring='f1_weighted')\n",
        "cv_accuracy_scores_train = cross_val_score(lr_model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_test = lr_model.predict(X_test)\n",
        "\n",
        "# Predict on train set\n",
        "y_pred_train = lr_model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on test set\n",
        "test_f1_score = classification_report(y_test, y_pred_test, output_dict=True)['weighted avg']['f1-score']\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "# Evaluate the model on train set\n",
        "train_f1_score = classification_report(y_train, y_pred_train, output_dict=True)['weighted avg']['f1-score']\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "\n",
        "# Print Results\n",
        "print(\"Logistic Regression Model Results with Count Vectorization and Balanced Dataset using SMOTE:\")\n",
        "print(\"-------------------------------------------------------\")\n",
        "print(\"CV=N Train Report F1-Score: {:.4f}\".format(cv_f1_scores_train.mean()))\n",
        "print(\"CV=N Train Accuracy: {:.4f}\".format(cv_accuracy_scores_train.mean()))\n",
        "print(\"Test Set Report F1-Score: {:.4f}\".format(test_f1_score))\n",
        "print(\"Test Set Accuracy: {:.4f}\".format(test_accuracy))\n",
        "print(\"Train Set Report F1-Score: {:.4f}\".format(train_f1_score))\n",
        "print(\"Train Set Accuracy: {:.4f}\".format(train_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd2DEyVH4POy",
        "outputId": "a64a7cb8-5998-4108-d541-622c82b6b262"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Model Results with Count Vectorization and Balanced Dataset using SMOTE:\n",
            "-------------------------------------------------------\n",
            "CV=N Train Report F1-Score: 0.7643\n",
            "CV=N Train Accuracy: 0.7648\n",
            "Test Set Report F1-Score: 0.7645\n",
            "Test Set Accuracy: 0.7647\n",
            "Train Set Report F1-Score: 1.0000\n",
            "Train Set Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SVM**"
      ],
      "metadata": {
        "id": "jVVEKv9k4RsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "preprocessed_data = pd.read_csv(\"subset_preprocessed_imdb_reviews.csv\")\n",
        "\n",
        "# Extract the preprocessed text data and labels\n",
        "processed_text = preprocessed_data['processed_text']\n",
        "labels = preprocessed_data['sentiment']\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "count_vectorizer = CountVectorizer(max_features=5000)  # Limiting the number of features to 5000\n",
        "\n",
        "# Perform Count Vectorization\n",
        "X = count_vectorizer.fit_transform(processed_text)\n",
        "\n",
        "# Apply SMOTE to balance the dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, labels)\n",
        "\n",
        "# Train/Test Split on balanced dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train SVM model\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Cross-validation for train set\n",
        "cv_f1_scores_train = cross_val_score(svm_model, X_train, y_train, cv=5, scoring='f1_weighted')\n",
        "cv_accuracy_scores_train = cross_val_score(svm_model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_test = svm_model.predict(X_test)\n",
        "\n",
        "# Predict on train set\n",
        "y_pred_train = svm_model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on test set\n",
        "test_f1_score = classification_report(y_test, y_pred_test, output_dict=True)['weighted avg']['f1-score']\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "# Evaluate the model on train set\n",
        "train_f1_score = classification_report(y_train, y_pred_train, output_dict=True)['weighted avg']['f1-score']\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "\n",
        "# Print Results\n",
        "print(\"Support Vector Machine (SVM) Model Results with Count Vectorization and Balanced Dataset using SMOTE:\")\n",
        "print(\"-------------------------------------------------------\")\n",
        "print(\"CV=N Train Report F1-Score: {:.4f}\".format(cv_f1_scores_train.mean()))\n",
        "print(\"CV=N Train Accuracy: {:.4f}\".format(cv_accuracy_scores_train.mean()))\n",
        "print(\"Test Set Report F1-Score: {:.4f}\".format(test_f1_score))\n",
        "print(\"Test Set Accuracy: {:.4f}\".format(test_accuracy))\n",
        "print(\"Train Set Report F1-Score: {:.4f}\".format(train_f1_score))\n",
        "print(\"Train Set Accuracy: {:.4f}\".format(train_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E63S7Yl4Ra5",
        "outputId": "b34c88eb-6743-47b9-99ec-d67fb4d756ae"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Machine (SVM) Model Results with Count Vectorization and Balanced Dataset using SMOTE:\n",
            "-------------------------------------------------------\n",
            "CV=N Train Report F1-Score: 0.7089\n",
            "CV=N Train Accuracy: 0.7104\n",
            "Test Set Report F1-Score: 0.7337\n",
            "Test Set Accuracy: 0.7353\n",
            "Train Set Report F1-Score: 0.9777\n",
            "Train Set Accuracy: 0.9777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Random Forest**"
      ],
      "metadata": {
        "id": "L0tg8qae4uae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "preprocessed_data = pd.read_csv(\"subset_preprocessed_imdb_reviews.csv\")\n",
        "\n",
        "# Extract the preprocessed text data and labels\n",
        "processed_text = preprocessed_data['processed_text']\n",
        "labels = preprocessed_data['sentiment']\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "count_vectorizer = CountVectorizer(max_features=5000)  # Limiting the number of features to 5000\n",
        "\n",
        "# Perform Count Vectorization\n",
        "X = count_vectorizer.fit_transform(processed_text)\n",
        "\n",
        "# Apply SMOTE to balance the dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, labels)\n",
        "\n",
        "# Train/Test Split on balanced dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest model\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Cross-validation for train set\n",
        "cv_f1_scores_train = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='f1_weighted')\n",
        "cv_accuracy_scores_train = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_test = rf_model.predict(X_test)\n",
        "\n",
        "# Predict on train set\n",
        "y_pred_train = rf_model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on test set\n",
        "test_f1_score = classification_report(y_test, y_pred_test, output_dict=True)['weighted avg']['f1-score']\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "# Evaluate the model on train set\n",
        "train_f1_score = classification_report(y_train, y_pred_train, output_dict=True)['weighted avg']['f1-score']\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "\n",
        "# Print Results\n",
        "print(\"Random Forest Model Results with Count Vectorization and Balanced Dataset using SMOTE:\")\n",
        "print(\"-------------------------------------------------------\")\n",
        "print(\"CV=N Train Report F1-Score: {:.4f}\".format(cv_f1_scores_train.mean()))\n",
        "print(\"CV=N Train Accuracy: {:.4f}\".format(cv_accuracy_scores_train.mean()))\n",
        "print(\"Test Set Report F1-Score: {:.4f}\".format(test_f1_score))\n",
        "print(\"Test Set Accuracy: {:.4f}\".format(test_accuracy))\n",
        "print(\"Train Set Report F1-Score: {:.4f}\".format(train_f1_score))\n",
        "print(\"Train Set Accuracy: {:.4f}\".format(train_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwJ-2XiH4yun",
        "outputId": "ad65f012-3d07-4c26-902f-68cdc88a5e71"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Model Results with Count Vectorization and Balanced Dataset using SMOTE:\n",
            "-------------------------------------------------------\n",
            "CV=N Train Report F1-Score: 0.7739\n",
            "CV=N Train Accuracy: 0.7673\n",
            "Test Set Report F1-Score: 0.7833\n",
            "Test Set Accuracy: 0.7843\n",
            "Train Set Report F1-Score: 1.0000\n",
            "Train Set Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Gradient Boosting**"
      ],
      "metadata": {
        "id": "InuXIqNb48gP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "preprocessed_data = pd.read_csv(\"subset_preprocessed_imdb_reviews.csv\")\n",
        "\n",
        "# Extract the preprocessed text data and labels\n",
        "processed_text = preprocessed_data['processed_text']\n",
        "labels = preprocessed_data['sentiment']\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "count_vectorizer = CountVectorizer(max_features=5000)  # Limiting the number of features to 5000\n",
        "\n",
        "# Perform Count Vectorization\n",
        "X = count_vectorizer.fit_transform(processed_text)\n",
        "\n",
        "# Apply SMOTE to balance the dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, labels)\n",
        "\n",
        "# Train/Test Split on balanced dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Gradient Boosting model\n",
        "gb_model = GradientBoostingClassifier()\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# Cross-validation for train set\n",
        "cv_f1_scores_train = cross_val_score(gb_model, X_train, y_train, cv=5, scoring='f1_weighted')\n",
        "cv_accuracy_scores_train = cross_val_score(gb_model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_test = gb_model.predict(X_test)\n",
        "\n",
        "# Predict on train set\n",
        "y_pred_train = gb_model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on test set\n",
        "test_f1_score = classification_report(y_test, y_pred_test, output_dict=True)['weighted avg']['f1-score']\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "# Evaluate the model on train set\n",
        "train_f1_score = classification_report(y_train, y_pred_train, output_dict=True)['weighted avg']['f1-score']\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "\n",
        "# Print Results\n",
        "print(\"Gradient Boosting Model Results with Count Vectorization and Balanced Dataset using SMOTE:\")\n",
        "print(\"-------------------------------------------------------\")\n",
        "print(\"CV=N Train Report F1-Score: {:.4f}\".format(cv_f1_scores_train.mean()))\n",
        "print(\"CV=N Train Accuracy: {:.4f}\".format(cv_accuracy_scores_train.mean()))\n",
        "print(\"Test Set Report F1-Score: {:.4f}\".format(test_f1_score))\n",
        "print(\"Test Set Accuracy: {:.4f}\".format(test_accuracy))\n",
        "print(\"Train Set Report F1-Score: {:.4f}\".format(train_f1_score))\n",
        "print(\"Train Set Accuracy: {:.4f}\".format(train_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmbsQguS4-t0",
        "outputId": "23025b77-a604-4c9d-e74a-908ad39a14a9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Model Results with Count Vectorization and Balanced Dataset using SMOTE:\n",
            "-------------------------------------------------------\n",
            "CV=N Train Report F1-Score: 0.8048\n",
            "CV=N Train Accuracy: 0.8052\n",
            "Test Set Report F1-Score: 0.8204\n",
            "Test Set Accuracy: 0.8214\n",
            "Train Set Report F1-Score: 0.8695\n",
            "Train Set Accuracy: 0.8697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TF-IDF Approach**"
      ],
      "metadata": {
        "id": "Uo4yvJ6b5DFH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Logistic Regression**"
      ],
      "metadata": {
        "id": "oBYVkB6X5FvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "preprocessed_data = pd.read_csv(\"subset_preprocessed_imdb_reviews.csv\")\n",
        "\n",
        "# Extract the preprocessed text data and labels\n",
        "processed_text = preprocessed_data['processed_text']\n",
        "labels = preprocessed_data['sentiment']\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limiting the number of features to 5000\n",
        "\n",
        "# Perform TF-IDF Vectorization\n",
        "X = tfidf_vectorizer.fit_transform(processed_text)\n",
        "\n",
        "# Apply SMOTE to balance the dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, labels)\n",
        "\n",
        "# Train/Test Split on balanced dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Cross-validation for train set\n",
        "cv_f1_scores_train = cross_val_score(lr_model, X_train, y_train, cv=5, scoring='f1_weighted')\n",
        "cv_accuracy_scores_train = cross_val_score(lr_model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_test = lr_model.predict(X_test)\n",
        "\n",
        "# Predict on train set\n",
        "y_pred_train = lr_model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on test set\n",
        "test_f1_score = classification_report(y_test, y_pred_test, output_dict=True)['weighted avg']['f1-score']\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "# Evaluate the model on train set\n",
        "train_f1_score = classification_report(y_train, y_pred_train, output_dict=True)['weighted avg']['f1-score']\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "\n",
        "# Print Results\n",
        "print(\"Logistic Regression Model Results with TF-IDF Vectorization and Balanced Dataset using SMOTE:\")\n",
        "print(\"-------------------------------------------------------\")\n",
        "print(\"CV=N Train Report F1-Score: {:.4f}\".format(cv_f1_scores_train.mean()))\n",
        "print(\"CV=N Train Accuracy: {:.4f}\".format(cv_accuracy_scores_train.mean()))\n",
        "print(\"Test Set Report F1-Score: {:.4f}\".format(test_f1_score))\n",
        "print(\"Test Set Accuracy: {:.4f}\".format(test_accuracy))\n",
        "print(\"Train Set Report F1-Score: {:.4f}\".format(train_f1_score))\n",
        "print(\"Train Set Accuracy: {:.4f}\".format(train_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lrXAs2Z5tYe",
        "outputId": "f72485ca-8330-445f-96b8-6fad4bebb190"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Model Results with TF-IDF Vectorization and Balanced Dataset using SMOTE:\n",
            "-------------------------------------------------------\n",
            "CV=N Train Report F1-Score: 0.8562\n",
            "CV=N Train Accuracy: 0.8563\n",
            "Test Set Report F1-Score: 0.8550\n",
            "Test Set Accuracy: 0.8552\n",
            "Train Set Report F1-Score: 0.9347\n",
            "Train Set Accuracy: 0.9347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM**"
      ],
      "metadata": {
        "id": "aMP6e2a75yn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "preprocessed_data = pd.read_csv(\"subset_preprocessed_imdb_reviews.csv\")\n",
        "\n",
        "# Extract the preprocessed text data and labels\n",
        "processed_text = preprocessed_data['processed_text']\n",
        "labels = preprocessed_data['sentiment']\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limiting the number of features to 5000\n",
        "\n",
        "# Perform TF-IDF Vectorization\n",
        "X = tfidf_vectorizer.fit_transform(processed_text)\n",
        "\n",
        "# Apply SMOTE to balance the dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, labels)\n",
        "\n",
        "# Train/Test Split on balanced dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train SVM model\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Cross-validation for train set\n",
        "cv_f1_scores_train = cross_val_score(svm_model, X_train, y_train, cv=5, scoring='f1_weighted')\n",
        "cv_accuracy_scores_train = cross_val_score(svm_model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_test = svm_model.predict(X_test)\n",
        "\n",
        "# Predict on train set\n",
        "y_pred_train = svm_model.predict(X_train)\n",
        "\n",
        "# Classification report for test set\n",
        "test_classification_report = classification_report(y_test, y_pred_test)\n",
        "\n",
        "# Confusion matrix for test set\n",
        "test_confusion_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "# Classification report for train set\n",
        "train_classification_report = classification_report(y_train, y_pred_train)\n",
        "\n",
        "# Confusion matrix for train set\n",
        "train_confusion_matrix = confusion_matrix(y_train, y_pred_train)\n",
        "\n",
        "# Print Results\n",
        "print(\"Support Vector Machine (SVM) Model Results with TF-IDF Vectorization and Balanced Dataset using SMOTE:\")\n",
        "print(\"-------------------------------------------------------\")\n",
        "print(\"CV=N Train Report F1-Score: {:.4f}\".format(cv_f1_scores_train.mean()))\n",
        "print(\"CV=N Train Accuracy: {:.4f}\".format(cv_accuracy_scores_train.mean()))\n",
        "print(\"Test Set Classification Report:\")\n",
        "print(test_classification_report)\n",
        "print(\"Test Set Confusion Matrix:\")\n",
        "print(test_confusion_matrix)\n",
        "print(\"Train Set Classification Report:\")\n",
        "print(train_classification_report)\n",
        "print(\"Train Set Confusion Matrix:\")\n",
        "print(train_confusion_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lbDvCB851EP",
        "outputId": "8665a9ce-c782-43a3-96ec-c897f88f5dd6"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Machine (SVM) Model Results with TF-IDF Vectorization and Balanced Dataset using SMOTE:\n",
            "-------------------------------------------------------\n",
            "CV=N Train Report F1-Score: 0.8582\n",
            "CV=N Train Accuracy: 0.8583\n",
            "Test Set Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.82      0.84       491\n",
            "    positive       0.84      0.88      0.86       517\n",
            "\n",
            "    accuracy                           0.85      1008\n",
            "   macro avg       0.85      0.85      0.85      1008\n",
            "weighted avg       0.85      0.85      0.85      1008\n",
            "\n",
            "Test Set Confusion Matrix:\n",
            "[[402  89]\n",
            " [ 60 457]]\n",
            "Train Set Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      1.00      1.00      2028\n",
            "    positive       1.00      1.00      1.00      2002\n",
            "\n",
            "    accuracy                           1.00      4030\n",
            "   macro avg       1.00      1.00      1.00      4030\n",
            "weighted avg       1.00      1.00      1.00      4030\n",
            "\n",
            "Train Set Confusion Matrix:\n",
            "[[2019    9]\n",
            " [   6 1996]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**"
      ],
      "metadata": {
        "id": "olInsDjD59XZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "preprocessed_data = pd.read_csv(\"subset_preprocessed_imdb_reviews.csv\")\n",
        "\n",
        "# Extract the preprocessed text data and labels\n",
        "processed_text = preprocessed_data['processed_text']\n",
        "labels = preprocessed_data['sentiment']\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limiting the number of features to 5000\n",
        "\n",
        "# Perform TF-IDF Vectorization\n",
        "X = tfidf_vectorizer.fit_transform(processed_text)\n",
        "\n",
        "# Apply SMOTE to balance the dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, labels)\n",
        "\n",
        "# Train/Test Split on balanced dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest model\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Cross-validation for train set\n",
        "cv_f1_scores_train = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='f1_weighted')\n",
        "cv_accuracy_scores_train = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_test = rf_model.predict(X_test)\n",
        "\n",
        "# Predict on train set\n",
        "y_pred_train = rf_model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on test set\n",
        "test_f1_score = classification_report(y_test, y_pred_test, output_dict=True)['weighted avg']['f1-score']\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "# Evaluate the model on train set\n",
        "train_f1_score = classification_report(y_train, y_pred_train, output_dict=True)['weighted avg']['f1-score']\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "\n",
        "# Print Results\n",
        "print(\"Random Forest Model Results with TF-IDF Vectorization and Balanced Dataset using SMOTE:\")\n",
        "print(\"-------------------------------------------------------\")\n",
        "print(\"CV=N Train Report F1-Score: {:.4f}\".format(cv_f1_scores_train.mean()))\n",
        "print(\"CV=N Train Accuracy: {:.4f}\".format(cv_accuracy_scores_train.mean()))\n",
        "print(\"Test Set Report F1-Score: {:.4f}\".format(test_f1_score))\n",
        "print(\"Test Set Accuracy: {:.4f}\".format(test_accuracy))\n",
        "print(\"Train Set Report F1-Score: {:.4f}\".format(train_f1_score))\n",
        "print(\"Train Set Accuracy: {:.4f}\".format(train_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWpixUpY5_cq",
        "outputId": "ea8f2cd8-6ec5-4cd8-eb30-13e3f67e0e4e"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Model Results with TF-IDF Vectorization and Balanced Dataset using SMOTE:\n",
            "-------------------------------------------------------\n",
            "CV=N Train Report F1-Score: 0.8240\n",
            "CV=N Train Accuracy: 0.8280\n",
            "Test Set Report F1-Score: 0.8343\n",
            "Test Set Accuracy: 0.8343\n",
            "Train Set Report F1-Score: 1.0000\n",
            "Train Set Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Gradient Boosting**"
      ],
      "metadata": {
        "id": "vAkmHmwL6t5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "preprocessed_data = pd.read_csv(\"subset_preprocessed_imdb_reviews.csv\")\n",
        "\n",
        "# Extract the preprocessed text data and labels\n",
        "processed_text = preprocessed_data['processed_text']\n",
        "labels = preprocessed_data['sentiment']\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limiting the number of features to 5000\n",
        "\n",
        "# Perform TF-IDF Vectorization\n",
        "X = tfidf_vectorizer.fit_transform(processed_text)\n",
        "\n",
        "# Apply SMOTE to balance the dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, labels)\n",
        "\n",
        "# Train/Test Split on balanced dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Gradient Boosting model\n",
        "gb_model = GradientBoostingClassifier()\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# Cross-validation for train set\n",
        "cv_f1_scores_train = cross_val_score(gb_model, X_train, y_train, cv=5, scoring='f1_weighted')\n",
        "cv_accuracy_scores_train = cross_val_score(gb_model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_test = gb_model.predict(X_test)\n",
        "\n",
        "# Predict on train set\n",
        "y_pred_train = gb_model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on test set\n",
        "test_f1_score = classification_report(y_test, y_pred_test, output_dict=True)['weighted avg']['f1-score']\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "# Evaluate the model on train set\n",
        "train_f1_score = classification_report(y_train, y_pred_train, output_dict=True)['weighted avg']['f1-score']\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "\n",
        "# Print Results\n",
        "print(\"Gradient Boosting Model Results with TF-IDF Vectorization and Balanced Dataset using SMOTE:\")\n",
        "print(\"-------------------------------------------------------\")\n",
        "print(\"CV=N Train Report F1-Score: {:.4f}\".format(cv_f1_scores_train.mean()))\n",
        "print(\"CV=N Train Accuracy: {:.4f}\".format(cv_accuracy_scores_train.mean()))\n",
        "print(\"Test Set Report F1-Score: {:.4f}\".format(test_f1_score))\n",
        "print(\"Test Set Accuracy: {:.4f}\".format(test_accuracy))\n",
        "print(\"Train Set Report F1-Score: {:.4f}\".format(train_f1_score))\n",
        "print(\"Train Set Accuracy: {:.4f}\".format(train_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR0RwzDJ6y18",
        "outputId": "56b33266-bdca-42bb-e1d2-7c872dbb7358"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Model Results with TF-IDF Vectorization and Balanced Dataset using SMOTE:\n",
            "-------------------------------------------------------\n",
            "CV=N Train Report F1-Score: 0.8010\n",
            "CV=N Train Accuracy: 0.8010\n",
            "Test Set Report F1-Score: 0.8106\n",
            "Test Set Accuracy: 0.8115\n",
            "Train Set Report F1-Score: 0.8939\n",
            "Train Set Accuracy: 0.8940\n"
          ]
        }
      ]
    }
  ]
}